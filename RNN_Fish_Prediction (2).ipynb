{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9zl_L9MAkpV"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/kaggle.json'"
      ],
      "metadata": {
        "id": "wGRKP6G4BQBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d crowww/a-large-scale-fish-dataset"
      ],
      "metadata": {
        "id": "1cPB24EGBQEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(\"a-large-scale-fish-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "rl2B4ijqBQHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIR = '/content/Fish_Dataset/Fish_Dataset'\n",
        "classes = [i for i in os.listdir(DIR) if '.' not in i]\n",
        "classes"
      ],
      "metadata": {
        "id": "UHj8YyhkBQJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "label = []\n",
        "path = []\n",
        "\n",
        "for dirname, _,filenames in os.walk(DIR):\n",
        "    for filename in filenames:\n",
        "        if os.path.splitext(filename)[-1]=='.png':\n",
        "            if dirname.split()[-1]!='GT':\n",
        "                label.append(os.path.split(dirname)[-1])\n",
        "                path.append(os.path.join(dirname,filename))\n",
        "\n",
        "df = pd.DataFrame(columns=['path','label'])\n",
        "df['path']=path\n",
        "df['label']=label"
      ],
      "metadata": {
        "id": "9qHVPHCFBQMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "0TutgXcZBQOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.path[0]"
      ],
      "metadata": {
        "id": "vr6IKScqBcao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tcCQ4-c2Bcdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "2Ph7NnW9BcgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "idx = 0\n",
        "plt.figure(figsize=(15,12))\n",
        "for unique_label in df['label'].unique():\n",
        "    plt.subplot(3, 3, idx+1)\n",
        "    plt.imshow(plt.imread(df[df['label']==unique_label].iloc[0,0]))\n",
        "    plt.title(unique_label)\n",
        "    plt.axis('off')\n",
        "    idx+=1"
      ],
      "metadata": {
        "id": "H6LFzRhBBcic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "4zuF-oaiBck7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "RgSlI0xaBcnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Flatten, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import TimeDistributed, Reshape\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "NsvwVNdXBcqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up ImageDataGenerator with rescaling for normalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augmentation settings for the training data\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255,                  # Rescale pixel values\n",
        "    validation_split=0.2,            # Split for validation data\n",
        "    # Data augmentation settings\n",
        "    rotation_range=20,               # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,           # Randomly shift images horizontally by 20%\n",
        "    height_shift_range=0.2,          # Randomly shift images vertically by 20%\n",
        "    shear_range=0.2,                 # Randomly shear images\n",
        "    zoom_range=0.2,                  # Randomly zoom images\n",
        "    horizontal_flip=True,            # Randomly flip images horizontally\n",
        "    fill_mode='nearest'              # Fill in missing pixels after transformations\n",
        ")\n",
        "\n",
        "# For validation and test data, we typically don't use augmentation\n",
        "test_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training dataset with augmentation\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(128, 128),          # Target size for images\n",
        "    color_mode='rgb',                # Use RGB color mode\n",
        "    class_mode='categorical',        # Multi-class classification\n",
        "    batch_size=32,                   # Batch size\n",
        "    shuffle=True,                    # Shuffle data\n",
        "    seed=42,                         # Seed for reproducibility\n",
        "    subset='training'                # Use the training subset\n",
        ")\n",
        "\n",
        "# Load validation dataset (without augmentation, just rescaling)\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(128, 128),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'             # Use the validation subset\n",
        ")\n",
        "\n",
        "# Load test dataset (no augmentation, just rescaling)\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(128, 128),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False                   # No shuffling for the test data\n",
        ")\n"
      ],
      "metadata": {
        "id": "Pg4dINsiBcsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_images.class_indices)\n",
        "display(val_images.class_indices)"
      ],
      "metadata": {
        "id": "KJMuCIfzBcur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# CNN + RNN architecture\n",
        "cnn_rnn_model = Sequential()\n",
        "\n",
        "# CNN layers for feature extraction\n",
        "cnn_rnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "cnn_rnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "cnn_rnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_rnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "cnn_rnn_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "cnn_rnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the CNN output\n",
        "cnn_rnn_model.add(Flatten())\n",
        "\n",
        "# Reshape to (batch_size, timesteps, features) before passing to LSTM\n",
        "cnn_rnn_model.add(Reshape((1, -1)))  # Reshape into 3D tensor (1 timestep, flattened features)\n",
        "\n",
        "# Add LSTM layers\n",
        "cnn_rnn_model.add(LSTM(64, return_sequences=True))\n",
        "\n",
        "# Global Average Pooling to reduce sequence dimension\n",
        "cnn_rnn_model.add(GlobalAveragePooling1D())\n",
        "\n",
        "# Final dense layers for classification\n",
        "cnn_rnn_model.add(Dense(512, activation='relu'))\n",
        "cnn_rnn_model.add(Dense(9, activation='softmax'))  # 9 classes\n",
        "\n",
        "# Compile the model\n",
        "cnn_rnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = cnn_rnn_model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=6\n",
        ")\n"
      ],
      "metadata": {
        "id": "DSdK-0TtBQWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = cnn_rnn_model.evaluate(train_images)\n",
        "print('Training accuracy:', train_acc)"
      ],
      "metadata": {
        "id": "5Dr3DfftNf6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = cnn_rnn_model.evaluate(val_images)\n",
        "print('Validation accuracy:', val_acc)"
      ],
      "metadata": {
        "id": "yeu78O68N4z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_rnn_model.save('fish_prediction_model.keras')"
      ],
      "metadata": {
        "id": "fkxCwYKON9EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "fPsSSZKWN9Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('training_hist.json','w') as f:\n",
        "  json.dump(history.history,f)"
      ],
      "metadata": {
        "id": "3ZJWbJ3wN9Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "wJpMMJJQN9MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, history.history['accuracy'], color='red', label='Training Accuracy')\n",
        "plt.plot(epochs, history.history['val_accuracy'], color='blue', label='Validation Accuracy')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.title('Visualization of Accuracy Result')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cnok0u1NN9Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = tf.keras.models.load_model('fish_prediction_model.keras')"
      ],
      "metadata": {
        "id": "pNddQ7uhOYI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rnn.predict(val_images)\n",
        "predicted_categories = tf.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "F77zmjePOYLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "image_path = '/content/Fish_Dataset/Fish_Dataset/Red Mullet/Red Mullet/00011.png'\n",
        "img = cv2.imread(image_path)\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #Converting BGR to RGB\n",
        "plt.imshow(img)\n",
        "plt.title('Test Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbC3-yRlOYOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.load_img(image_path,target_size=(128,128))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "predictions = rnn.predict(input_arr)"
      ],
      "metadata": {
        "id": "iloDR9AlOYQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "7E1aoZP1OYTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_index = np.argmax(predictions) #Return index of max element\n",
        "print(result_index)"
      ],
      "metadata": {
        "id": "awz4tHYvN9RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = val_images.class_indices\n",
        "\n",
        "class_names = list(class_indices.keys())\n",
        "\n",
        "print(\"Class Names:\", class_names)"
      ],
      "metadata": {
        "id": "OreAgW-lO0-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_prediction = class_names[result_index]\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Fish Name: {model_prediction}\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tLglds90O1BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "\n",
        "y_pred = rnn.predict(val_images)\n",
        "predicted_categories = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_true = val_images.classes\n",
        "\n",
        "cm = confusion_matrix(y_true, predicted_categories)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(val_images.class_indices.keys()), yticklabels=list(val_images.class_indices.keys()))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, predicted_categories, target_names=list(val_images.class_indices.keys())))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "with open('training_hist.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "for i in range(5):\n",
        "    img_path = val_images.filepaths[i]\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {class_names[predicted_categories[i]]}, True: {class_names[y_true[i]]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iEbcZev9O1Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
        "y_pred_bin = label_binarize(predicted_categories, classes=np.arange(len(class_names)))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(len(class_names)):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c-xOlMRYO1Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Predict the classes on the test set\n",
        "predictions = rnn.predict(test_images)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "# True labels\n",
        "true_labels = test_images.classes\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_images.class_indices.keys(), yticklabels=test_images.class_indices.keys())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1EuIiLGfPcBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='label', data=df, order=class_names)\n",
        "plt.title('Class Distribution in the Dataset')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Fish Species')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v-xDmyBUPcE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(len(class_names)):\n",
        "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred[:, i])\n",
        "    plt.plot(recall, precision, lw=2, label=f'{class_names[i]}')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "po95L5PZPcH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uwm6EISMPcKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}